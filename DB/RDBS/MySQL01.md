MySQL数据库
==

## 1. 数据表设计

### 1.1 三大范式
- 第一范式（原子性）: 数据表中每列必须是不可拆分的最小单元
- 第二范式（唯一性）: 非主键列完全依赖于主键,而不能是依赖于主键的一部分
- 第三范式（独立性）: 非主键列只依赖于主键,不依赖于其他非主键

### 1.2 反范式
- 在设计数据库结构的时候，要尽量遵守三范式，如果不遵守，必须有足够的理由。比如性能。
- 事实上我们经常会为了性能而妥协数据库的设计。

### 1.3 其他思考
- 主键自增: 如果不设置主键，InnoDB会选择一个唯一键作为主键、如果没有唯一键，会生成一个隐式主键
- 字段not null:  null会占用更多字节，且在程序中造成很多和预期不符合的情况


## 2. 数据类型问题

### 2.1 整数类型

#### 类型介绍
- 包括TINYINT、SMALLINT、MEDIUMINT、INT、BIGINT，分别表示1字节、2字节、3字节、4字节、8字节整数
- 何整数类型都可以加上UNSIGNED属性，表示数据是无符号的，即非负整数

#### 长度
- 整数类型可以被指定长度，例如：INT(11)表示长度为11的INT类型。 每个类型占用空间是固定的（和展示长度无关）
- 长度在大多数场景是没有意义的，它不会限制值的合法范围，只会影响显示字符的个数，而且需要和UNSIGNED ZEROFILL属性配合使用才有意义。

### 2.2 实数类型
#### 类型介绍
- 包括FLOAT、DOUBLE、DECIMAL
- DECIMAL可以用于存储比BIGINT还大的整型，能存储精确的小数。
- 而FLOAT和DOUBLE是有取值范围的，并支持使用标准的浮点进行近似计算。
- FLOAT类型数据可以存储至多8位十进制数，并在内存中占4字节。
- DOUBLE类型数据可以存储至多18位十进制数，并在内存中占8字节。
- 计算时FLOAT和DOUBLE相比DECIMAL效率更高一些，DECIMAL你可以理解成是用字符串进行处理。

### 2.3 字符串类型
#### 类型介绍
- 包括VARCHAR、CHAR、TEXT、BLOB

#### VARCHAR
- VARCHAR用于存储可变长字符串，它比定长类型更节省空间
- VARCHAR使用额外1或2个字节存储字符串长度。列长度小于255字节时，使用1字节表示，否则使用2字节表示。
- VARCHAR存储的内容超出设置的长度时，内容会被截断

#### CHAR
- CHAR是定长的，根据定义的字符串长度分配足够的空间。
- CHAR会根据需要使用空格进行填充方便比较。
- CHAR适合存储很短的字符串，或者所有值都接近同一个长度。
- CHAR存储的内容超出设置的长度时，内容同样会被截断。

#### 使用策略
- 对于经常变更的数据来说，CHAR比VARCHAR更好，因为CHAR不容易产生碎片
- 对于非常短的列，CHAR比VARCHAR在存储空间上更有效率
- 使用时要注意只分配需要的空间，更长的列排序时会消耗更多内存
- 尽量避免使用TEXT/BLOB类型，查询时会使用临时表，导致严重的性能开销。【其他自己扩展】

### 2.4 枚举类型（ENUM）

#### 类型描述
- 把不重复的数据存储为一个预定义的集合。
- 有时可以使用ENUM代替常用的字符串类型。
- ENUM存储非常紧凑，会把列表值压缩到一个或两个字节。
- ENUM在内部存储时，其实存的是整数。
- 尽量避免使用数字作为ENUM枚举的常量，因为容易混乱。排序是按照内部存储的整数

### 2.5 日期和时间类型
#### 类型描述
- 尽量使用timestamp，空间效率高于datetime
- datetime占用8个字节，时间范围从 1000-01-01 00:00:00 ~ 9999-12-31 23:59:59
- TIMESTAMP 4个字节， 时间范围1980-01-01 00:00:01 UTC ~ 2040-01-19 03:14:07 UTC 
- 用整数保存时间戳通常不方便处理。如果需要存储微妙，可以使用bigint存储。


## 3. sql运行原理

### 3.1 执行过程
- 客户端--连接器--(查询缓存)--分析器--优化器--执行器-存储引擎

### 3.2 Server层
#### 包含的功能
- Server层包括连接器、查询缓存、分析器、优化器、执⾏器等，涵盖MySQL的⼤多数核⼼服务功能
- 以及所有的内置函数（如⽇期、时间、数学和加密函数等）
- 所有跨存储引擎的功能都在这⼀层实现，⽐如存储过程、触发器、视图等

#### 连接器
- 管理连接以及权限验证

#### 查询缓存
- 命中则直接返回结果
- 你可以将参数query_cache_type设置成 DEMAND，这样对于默认的SQL语句都不使⽤查询缓存
- MySQL 8.0开始删除了查询缓存功能

#### 分析器
- 词法分析，语法分析
- 列不存在也会在此处报错

#### 优化器
- 执行计划生成、索引选择

#### 执行器
- 也会验证个表T有没有执⾏查询的权限
- 操作引擎，返回结果

### 3.3 存储引擎
#### 功能描述
- 不同引擎共用server层
- 存储数据、提供读写接口
- 存储引擎模式是插件式的
- MySQL中的数据、索引以及其他对象是如何存储的，是一套文件系统的实现

#### 有哪些
- InnoDB
- - 支持ACID事务、行级别锁、MVCC、外键
- - 它的设计的目标就是处理大数据容量的数据库系统
- - 它从MySQL 5.5.5版本开始成为了默认存储引擎
- MyISAM
- - (原本Mysql的默认引擎)：不提供事务的支持，也不支持行级锁和外键。
- Memory
- - 所有的数据都在内存中，数据的处理速度快，但是安全性不高。
- Archive等等

#### MyISAM与InnoDB区别
- 存储结构
- -  MyISAM 每张表被存放在三个文件：frm-表格定义、MYD(MYData)-数据文件、MYI(MYIndex)-索引文件
- - InnoDB 所有的表都保存在同一个数据文件中（也可能是多个文件，或者是独立的表空间文件）
- - InnoDB表的大小只受限于操作系统文件的大小，一般为2GB
- 存储空间
- - MyISAM可被压缩，存储空间较小
- - InnoDB的表需要更多的内存和存储，它会在主内存中建立其专用的缓冲池用于高速缓冲数据和索引
- 可移植性、备份及恢复
- - 由于MyISAM的数据是以文件的形式存储，所以在跨平台的数据转移中会很方便。在备份和恢复时可单独针对某个表进行操作
- - 免费的方案可以是拷贝数据文件、备份 binlog，或者用 mysqldump，在数据量达到几十G的时候就相对痛苦了
- 文件格式
- - MyISAM 数据和索引是分别存储的，数据.MYD，索引.MYI
- - InnoDB 数据和索引是集中存储的，.ibd
- 记录存储顺序
- - MyISAM 按记录插入顺序保存
- - InnoDB 按主键大小有序插入
- 外键与事务
- - MyISAM都不支持，InnoDB支持
- 锁支持
- - MyISAM表级别锁，InnoDB支持行级锁、表级别锁，锁定力度小、并发能力高
- 索引实现方式
- - B+树索引，myisam 是堆表； B+树索引，Innodb 是索引组织表
- - MyISAM索引的叶子节点存储的是行数据地址，需要再寻址一次才能得到数据
- - InnoDB索引是聚簇索引，MyISAM索引是非聚簇索引。
- - InnoDB的主键索引的叶子节点存储着行数据，因此主键索引非常高效。
- - InnoDB非主键索引的叶子节点存储的是主键和其他带索引的列数据，因此查询时做到覆盖索引会非常高效
- 哈希索引、全文索引
- - InnoDB支持自适应hash索引，不支持全文索引
- - MyISAM支持全文索引、不支持哈希索引

### 3.4 InnoDB引擎的关键特性
#### 3.4.1 插入缓冲（insert buffer）

##### Insert  Buffer
- 行记录在自增主键索引的插入是顺序的，但是在辅助索引并不是。这种辅助索引索引页的离散随机读取会导致插入操作性能插入下降
- InnoDB缓冲池中有Insert Buffer信息，但是Insert Buffer和数据页一样，也是物理页的一个组成部分
- 对于非聚集索引的插入或者更新操作，不是每一次直接插入到索引页中，而是先判定插入的非聚集索引页是否在缓冲池中，若在则直接插入；
- 如不在则先放入到 Insert Buffer中。然后再以一定的频率和情况进行Insert Buffer和辅助索引页子节点的merge操作
- 这时通常能将多少插入合并到一个操作中(因为在一个索引页中), 这就大大提高了对于非聚集索引的性能
- Insert Buffer的使用必须同时满足两个条件。1. 索引是辅助索引；2. 索引不是唯一的（不需要经过离散读取的索引页唯一性查找）
- Insert Buffer存在的问题：在写密集的情况下、插入缓冲会占用过多的缓冲池内存（innodb_buffer_pool）
- 默认最大可以占用到1/2的缓冲池内存,Percona发布一些patch来修正这个情况。 可以修改IBUF_POOL_PER_MAX_SIZE的值为x, 代表最大只能使用缓冲池内存的1/x

##### Change Buffer
-  InnoDB从1.0.x版本开始引入了Change Buffer。对DML操作-insert、delete、update都进行缓冲。分别是：Insert Buffer、Delete Buffer、Purge Buffer。
- Change Buffer使用的对象依然是非唯一的辅助索引
- 对一条记录进行update操作可能分为两个过程:1.将记录标记为已删除;2.真正将记录删除。
- 因此delete Buffer对update操作的第一个过程，Purge Buffer对应update操作的第二个过程
- 可以通过参数innodb_change_buffering来开启各种Buffer的选项。该参数的可选值有:inserts、deletes、purges、all、none。
- - changes表示启用inserts和deletes，all表示启用所有，none表示都不启用。默认all
- 在InnoDB 1.2.x还可以通过参数innodb_change_buffer_max_size(百分比)来控制最大使用的内存数量

##### Merge Insert Buffer
- 发生merge的场景
- - 1.辅助索引页被读取到缓冲池时;
- - 2.Insert Buffer Bitmap页追踪到该辅助索引页页无可用空间;
- - 3.Master Thread; 在Master Thread线程中每秒或每10秒进行一次Merge Insert Buffer的操作

#### 3.4.2 二次写（double write）
- 对页面拷贝副本，提高数据页的可靠性，当写失效时，通过副本页还原原页，再进行redo
- doublewrite由 内存中的doublewrite buffer (2MB) 和物理磁盘上共享表空间中连续的128个页，即两个区（2MB)组成

#### 3.4.3 自适应哈希索引（ahi）
- 如果建立哈希索引的检索速度比B+树检索的速度快，则建立哈希索引 AHI。
- AHI 有如下要求：对页面的访问模式（长训的条件）必须是一样的
- 哈希索引只能用来等值查询，不能用来做范围查询。

#### 3.4.4 异步IO
- AIO 用户可以连续发送多条IO请求，不需要等待其执行结果，直到所有请求都发送完成了再等待结果。另外可以将多个IO合并成一个IO。
- InnoDB提供内核级别的AIO支持，成为Native AIO。启用Native AIO, 恢复速度提升75%。
- 在InnoDB存储引擎中，read ahead方式的读取都是通过AIO完成，脏页的刷新，也是通过AIO完成。

#### 3.4.5 刷新紧邻页
- 工作原理：当刷新一个脏页时，InnoDB存储引擎会检测该页所在的区（extent)的所有项，如果有脏页，则一起刷新。
- 这样做的好处是通过AIO可以将多个IO写操作合并为一个IO操作。该工作机制在传统机械磁盘下有显著优势
- 这些特性为InnoDB存储引擎带来了更好的性能、更高的可靠性。


## 4. redo log以及binlog

### 4.1 WAL（Write Ahead Logging）
- 先写日志（redolog）再写磁盘不忙时候再写账本
- binlog是server层的日志（归档日志），binlog日志是逻辑日志、binlog日志可以追加写入
- redo log是InnoDB引擎特有的，redo log 是物理日志，redo log是循环写的，空间固定会⽤完

### 4.2 binlog三种格式
#### statement
- statement模式下,记录单元为语句，每一条会修改数据的sql都会记录在binlog中
- 不需要记录每一行的变化，减少了binlog日志量，节约了IO，提高性能
- 由于sql的执行是有上下文的,因此在保存的时候需要保存相关的信息
- 同时还有一些使用了函数之类的语句无法被记录复制

#### row
- row级别下,记录单元为每一行的改动，基本是可以全部记下来
- 由于很多操作,会导致大量行的改动(比如alter table),因此这种模式的文件保存的信息太多,日志量太大
- 新版的MySQL中对row级别也做了一些优化,当表结构发生变化的时候,会记录语句而不是逐行记录.

#### mixed
- 一种折中的方案,普通操作使用statement记录,当无法使用statement的时候使用row

### 4.3 binglog写入机制
事务执行过程中写到binlog cahce，事务提交时候，再把binlog cache写到binlog文件

####  write 和fsync的时机，是由参数sync_binlog控制
- write指的就是指把⽇志写⼊到⽂件系统的page cache
- 每个线程都有自己的binlog cache 但是共用一份binlog

#### sync_binlog配置
- 0表示每次提交事务都只weite不fsync
- 1表示每次提交事务都会fsync
- N（N>1），表示每次提交事务都write，但积累N个事务后才fsync

### 4.4 redolog写入机制
事务执行过程中，先写入redo log buffer

#### redo log三种状态
- 存在 redo log buffer内存中，物理上是在 mysql进程内存中
- 写到磁盘write 但是没有持久化fsync，物理上是在文件系统的page_chage
- 持久化到磁盘，对应的是hard disk
- InnoDB有⼀个后台线程，每隔1秒，就会把redo log buffffer中的⽇志，调⽤write写到⽂件系统的 page cache，然后调⽤fsync持久化到磁盘。一个没提交的事务的redo log也可能已经持久化到磁盘了

#### innodb_flush_log_at_trx_commit参数
- 0 表示每次事务提交都只把redo log留在redo log buffer中
- 1 表示每次事务提交都把 relo log直接持久化到磁盘
- 2 表示每次事务提交时都只是把 redo log 写到page cache

#### sync_binlog 与 innodb_flush_log_at_trx_commit参数 双1配置
- 正常线上推荐双1配置
- 非双1场景 
- - 业务高峰期、备库复制延迟、⽤备份恢复主库的副本、批量导入数据
- - ⼀般情况下，把⽣产库改成“⾮双1”配置，是设置innodb_flflush_logs_at_trx_commit=2、 sync_binlog=1000。

### 4.5 日志逻辑许序列号与组提交

#### 日志逻辑序列号 log sequence number ， LSN
- LSN单调递增，对应redo_log的一个个写入点，每次写入长度为lenght的redo log，LSN的值就会加上length
- LSN也会写到InnoDB的数据⻚中，来确保数据⻚不会被多次执⾏重复的redo log

#### 组提交（group commit）
- 多事务时，leader事务提交写盘的时候会带LSN，将LSN低于写入值的都持久化到磁盘，这时候其他相关事务就可以直接返回不需要重复操作

### 4.6 更新两阶段提交

#### 更新流程
- 1. 取id=1的行，在内存直接返回，不在则从磁盘读入内存 
- 2. 将行的c字段值加1，写入新行， 新行更新到内存
- 3. 写入 redo log，此时redo log 处于prepare阶段
- 4. 写入 binlog
- 5. 提交事务，将redo log改成commit状态

#### 崩溃恢复
- 处于3-4阶段崩溃，恢复之后会回滚
- 处于4-5阶段崩溃
- - 恢复之后会如果redo log里事务是完成的，则直接提交；
- - 如果redo log里的事务只有完成的prepare，则通过binlog记录判断是回滚还是提交
- - binlog有完整格式
- - - redo log和 binlog有共同的数据字段 XID

### 4.7 binlog分析
可以使用 mysqlbinlog 命令分析 binlog日志文件


## 5. 数据库事务

### 5.1 事务特性

#### ACID特性
- A=Atomicity 原子性
- - 要么全部成功、要么全部失败
- C=Consistency 一致性
- - 系统(数据库)总是从一个一致性的状态转移到另一个一致性的状态,不会存在中间状态
- I=Isolation 隔离性
- -  通常来说:一个事务在完全提交之前,对其他事务是不可见的
- D=Durability 持久性
- - 一旦事务提交,那么就永远是这样子了,哪怕系统崩溃也不会影响到这个事务的结果

### 5.2 隔离级别基础

#### 定义多种隔离性原因
- 事务隔离的不同程度，实际上是通过不同的上锁要求来控制事务并发的能力。所以谈论事务隔离的时候，我们首先要想到“锁”和“并发”。
- 上锁最严格，则意味着事务之间隔离性性越好，效率最低，但是自然也是最安全的。
- 上锁要求宽松，不仅减少了锁的开销，也提升了事务并发的能力，但是也增大了死锁的概率，以及并发带来的不可重复度、脏读和幻读等问题

#### 基于锁的事务隔离级别
- 一般我们说的事务隔离级别都是基于锁的实现方式。这说明也存在无锁的事务并发控制，这是另外的一种事务隔离性，后面会说。

### 5.3 低隔离级别问题

#### 脏读(Dirty Read)：
- 一个事务单元A的读操作读到了另一个未提交的事务单元B写入的数据（其他事务可能回滚，看到的数据则不准确）。

#### 不可重复读取(Non-Repeatable Read): 
- 一个事务单元中两次读同一行数据，这两次读到的数据不一样。（不可重复读重点是修改，同一个事务中再次读取发现值不同）
- 在基于锁的并发控制中“不可重复读”现象发生在当执行SELECT 操作时没有获得读锁或者SELECT操作执行完后马上释放了读锁；
- 多版本并发控制中当没有要求一个提交冲突的事务回滚也会发生“不可重复读”现象。

#### 幻读(Phantom Read)：
- 幻读主要指1个事务单元针对同一个范围的两次SELECT结果不同。存在不可重复读的问题一般也必然存在幻读问题了。
- 区别不可重复读，幻读主要指范围select时由于隔离性原因造成的执行结果不同。
- “幻读”是不可重复读的一种特殊场景：当事务1两次执行SELECT ... WHERE检索一定范围内数据的操作中间，事务2在这个表中创建了(如INSERT)了一行新数据，这条新数据正好满足事务1的“WHERE”子句
- 幻读的重点在与新增，其他事务新增导致本事务查询数据多出来了

#### 更新丢失：
- 两个事务单元都同时更新一行数据，一个事务单元对数据的更新把另一个事务单元对数据的更新覆盖了。
- 这是因为系统没有执行任何的锁操作，因此并发事务并没有被隔离开来

### 5.4 隔离级别具体类型

#### 重要说明
- 下面讨论的四种隔离级别是由ANSI/ISO SQL定义的标准。

#### 未提交读(read uncommitted)
- 小总结：读锁、写锁，处理好一条记录均马上释放，还没有范围锁。事务间完全没隔离，所有问题均可能出现
- 读未提交是指，⼀个事务还没提交时，它做的变更就能被别的事务看到。 可能会导致脏读、幻读、或不可重复读

#### 已提交读(read committed)
- 小总结：读已提交，读锁SELECT后马上释放，没有范围锁，写锁一直保持到事务结束，会不可重复读，当然也包括幻读
- 其他事务只能读取到本事务已经提交的部分，有不可重复读问题
- Oracle等多数数据库默认都是该级别 (不重复读)， MySQL的InnoDB引擎不是
- MySQL的InnoDB的区别
- - 一般情况下只有行锁，没有间隙锁部分
- - 为了解决数据和日志不一样问题，可以使用该隔离级别加binlog格式设置为row
- MySQL实际使用
- - 但在实际使用过程当中，MySQL做了一些改进，在MySQL Server过滤条件，发现不满足后，会调用unlock_row方法，把不满足条件的记录释放锁 (违背了二段锁协议的约束)。
- - 这样做，保证了最后只会持有满足条件记录上的锁，但是每条记录的加锁操作还是不能省略的。
- - 可见即使是MySQL，为了效率也是会违反规范的。（参见《高性能MySQL》中文第三版p181）
- - 所以对一个数据量很大的表做批量修改的时候，如果无法使用相应的索引，MySQL Server过滤数据的的时候特别慢，就会出现虽然没有修改某些行的数据，但是它们还是被锁住了的现象。
- - 这种情况同样适用于MySQL的默认隔离级别RR。

#### 可重复读(repeatable read)
- 小总结：可重复读，一个事务内读写锁全部保持到事务结束，缺少范围锁，会有幻读
- 对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改，可以阻止脏读和不可重复读，但幻读仍有可能发生
- InnoDB用间隙锁解决幻读问题(Gap Lock)
- - 跟间隙锁存在冲突关系的，是 "往这个间隙中插⼊⼀个记录" 这个操作
- - 间隙锁和⾏锁合称next-key lock，每个next-key lock都是前开后闭区间
- InnoBD引擎中
- - InnoDB引擎默认使用该隔离级别
- - InnoDB在该隔离级别下使用了间隙锁来解决幻读的问题
- innodb自动使用间隙锁的条件
- - InnoDB 间隙锁只在可重复读的隔离级别下存在 
- - 检索条件必须有索引（没有索引的话，mysql会全表扫描，那样会锁定整张表所有的记录，包括不存在的记录，此时其他事务不能修改不能删除不能添加）
- 间隙锁加锁规则
- - 原则一 加锁基本单位是next-key lock
- - 原则二 查找过程中访问到的对象才会加锁
- - 优化一 索引上的等值查询，给唯⼀索引加锁的时候，next-key lock退化为⾏锁；
- - 优化二 索引上的等值查询，向右遍历时且最后⼀个值不满⾜等值条件的时候，next-key lock退化为间隙锁 
- - ⼀个bug：唯⼀索引上的范围查询会访问到不满⾜条件的第⼀个值为⽌

#### 可序列化(serializable )
- 要求在选定对象上的读锁和写锁保持直到事务结束后才能释放。范围锁也持续到事务结束（纯锁机制下）
- 小总结：可序列化，一个事务内读写锁全部保持到事务结束，并且存在范围锁
- 可序列化不同事务之间完全隔离，针对同一行记录的读写不会并行，不会有隔离级别低带来的问题。但并发性能会极速下降

### 5.5 隔离级别查看修改

#### 查看
- 通过查询数据库提供的系统变量 tx_isolation 或 transaction_isolation 的值即可获取当前的事务隔离级别
- 使用如下命令   show variables like "%tx_isolation%";  
- SELECT @@global.tx_isolation; //查询全局事务SELECT @@session.tx_isolation; //查询当前会话事务

#### 修改
- 使用 set session transaction isolation level read commit;   （设置当前会话的隔离级别）
- 使用 set global transaction isolation level read commit;   （设置全局会话的隔离级别，不会影响当前已经打开其他的会话）
- 通过命令 set transaction isolation level 可设置下一次事务操作的隔离级别，该设置会随着下一次事务的提交而失效

### 5.6 MVCC多版本并发控制

#### 锁机制
InnoDB实现了行锁、页锁、表锁

##### 根据读写
- 共享锁（读锁，可以加多个）
- 排他锁（写锁，只可以加一个）

##### 两阶段锁协议
- 必要性
- - 数据库遵循的是两段锁协议，将事务分成两个阶段，加锁阶段和解锁阶段（所以叫两段锁）
- - 这种方式虽然无法避免死锁，但是两段锁协议可以保证事务的并发调度是串行化（串行化很重要，尤其是在数据恢复和备份的时候）的。
- 加锁阶段：
- - 在该阶段可以进行加锁操作。
- - 在对任何数据进行读操作之前要申请并获得S锁（共享锁，其它事务可以继续加共享锁，但不能加排它锁），
- - 在进行写操作之前要申请并获得X锁（排它锁，其它事务不能再获得任何锁）。
- - 加锁不成功，则事务进入等待状态，直到加锁成功才继续执行。
- 解锁阶段：
- -  当事务释放了一个封锁以后，事务进入解锁阶段，在该阶段只能进行解锁操作不能再进行加锁操作。

##### 根据锁范围
- 全局锁
- - 全局锁的典型使⽤场景是，做全库逻辑备份
- - 命令:  Flush tables with read lock (FTWRL)
- 表级别锁
- - 表锁和元数据锁(MDL)
- - - 访问表的时候会自动 MDL（保证读写正确性）
- - - 逻辑备份时候遇到binlog的DDL语句后流程
- - online DDL
- - - 三种方式以及坑
- 行级别锁
- - 两阶段锁协议
- - - InnoDB 行锁在需要的时候才加，等事务结束才释放
- - - 业务处理时候： 如果事务要锁多行，要把最可能造成冲突与影响并发的锁尽量后置
- 间隙锁
- - InnoDB 关闭间隙锁
- - - 有两种方式显式关闭gap锁：（除了外键约束和唯一性检查外，其余情况仅使用record lock）
- - - A. 将事务隔离级别设置为RC B. 将参数innodb_locks_unsafe_for_binlog设置为1

##### 死锁和死锁检测

死锁解决
- 等待与超时
- - InnoDB的innodb_lock_wait_timeout默认配置是 50s
- 主动检测与回滚
- - 热点行更新导致死锁、 死锁检测耗费大量的cpu资源
- - 临时关闭死锁检测(极度不推荐)、控制并发度
- - 业务设计上拆解热点行为多条记录

死锁业务解决方案
- 如果不同程序会并发存取多个表，尽量约定以相同的顺序访问表，可以大大降低死锁机会
- 例子：两个账户同时操作，如果是交叉更新，遇到并发会死锁。如果按照固定顺序，比如主键大小来排序更新，则可以降低死锁概率
- 在同一个事务中，尽可能做到一次锁定所需要的所有资源，减少死锁产生概率
- 对于非常容易产生死锁的业务部分，可以尝试使用升级锁定颗粒度，通过表级锁定来减少死锁产生的概率


#### InnoDB的MVCC
是通过在每行纪录后面保存两个隐藏的列来实现的，
隐藏列保存行的创建版本号以及过期（删除）版本号。
每次更新都会记录回滚操作，回滚日志在不需要的时候会删除，回滚日志影响长事务效率。
每开始一个新的事务，系统版本号都会自动递增。

##### 快照读 / 当前读
- 快照读（搜索时时候不会加锁）
- - 一般的 select * from ... where ...  查询语句都是快照读
- 当前读（会在搜索的时候加锁）
- - select * from ... where ... for update
- - elect * from .... where ... lock in share mode
- - update .... set .. where ...  与 delete from. . where ..

##### undo log
- 定义
- - undo log主要记录数据的逻辑变化，为了在发生错误时回滚之前的操作，需要将之前的操作都记录下来，然后在发生错误时才可以回滚
- 存储位置
- - 在InnoDB存储引擎中，undo log存储在回滚段(Rollback Segment)中
- - 每个回滚段记录了1024个undo log segment，而在每个undo log segment段中进行undo 页的申请
- - 在5.6以前，Rollback Segment是在共享表空间里的
- - 5.6.3之后，可通过 innodb_undo_tablespace设置undo存储的位置
- undo log的写入时机
- - DML操作修改聚簇索引前，记录undo log
- - 二级索引记录的修改，不记录undo log
- 作用
- - 事务回滚
- - MVCC
- 与redo log对比
- - undo log是逻辑日志，对事务回滚时，只是将数据库逻辑地恢复到原来的样子
- - 而redo log是物理日志，记录的是数据页的物理变化，显然undo log不是redo log的逆过程

##### MVCC流程
- 开始事务
- 记录数据行数据到undo log（未考虑redo log）
- 更新数据
- undo log写到磁盘
- 将数据写入磁盘
- 提交事务

### 5.7 事务启动方式
- 显式声明 begain commit
- set autocommit=0

## 6. 索引原理

### 6.1 B+树

#### 基于多路平衡查找树
- 专门为了外存储设备设计的
- 磁盘读取以块为单位，同块数据会一次性读取
- 存储引擎页概念（磁盘管理的最小单位）、InnoDB引擎默认每个页大小为16k
- 每个多路平衡查找树的节点占用一个磁盘块或页空间，可以减少IO次数
- 节点数据页的分页与合并
- InnoDB存储引擎设计时根节点常驻内存

#### 叶子结点存记录
- 聚簇索引
- - InnoDB引擎的主键索引，叶子节点存数据记录
- 非聚簇索引
- - 其他索引，叶子节点存主键
- B+树的叶子节点使用指针顺序连接在一起

#### 扩展知识（B*树）
- B*树是B+树的变体，在B+树的非根和非叶子结点再增加指向兄弟的指针；
- B*树定义了非叶子结点关键字个数至少为(2/3)*M，即块的最低使用率为2/3（代替B+树的1/2）。
- MySQL未使用该组织方式
- - 但是每条数据的插入与删除都会影响到多层级节点的前后指针，这会有一部分管理难度 以及 性能消耗

#### MySQL8.0 引入函数索引

内部是依据虚拟列来实现的
- 虚拟列不存储在数据行中，但虚拟列的元数据信息会存在于相关系统表中，对虚拟列的添加或者删除只会涉及这些系统表，不会导致数据表的重建，所以效率很高
- 需要注意，不能建立虚拟列和真实列的联合索引

### 6.2 Hash索引

#### Hash表
- 不适合做范围查询，而且数据不一定均衡

#### InnoDB自适应hash索引
- InnoDB用户无法手动创建哈希索引，这一层上说，InnoDB确实不支持哈希索引 
- InnoDB会自调优(self-tuning)，如果判定建立自适应哈希索引(Adaptive Hash Index, AHI)，能够提升查询效率，InnoDB自己会建立相关哈希索引，这一层上说，InnoDB又是支持哈希索引的

#### 自适应hash索引原理
- 在MySQL运行的过程中，如果InnoDB发现，有很多SQL存在很长的寻路，并且有很多SQL会命中相同的页面(page)，
- InnoDB会在自己的内存缓冲区(Buffer)里，开辟一块区域，建立自适应哈希索引AHI，以加速查询
- 从这个层面上来说，InnoDB的自使用哈希索引，更像“索引的索引”，毕竟其目的是为了加速索引寻路

#### 开启自适应hash的影响
- 既然是哈希，key是索引键值（或者键值前缀）。value是索引记录页面位置。
- 系统自己判断“应该可以加速查询”而建立的，不需要用户手动建立，故称“自适应”。
- 不是一定能加速，有时候会误判。
- - 很多单行记录查询（例如passport，用户中心等业务）索引范围查询,（此时AHI可以快速定位首行记录）所有记录内存能放得下
- hash自适应索引会占用innodb buffer pool

### 6.3 表索引优化与分析

#### 索引覆盖查询
- 非索引覆盖会再次回表查询提取数据

#### 创建索引考虑的因素
- 常用来查询排序的字段、且区分度比较大的
- 联合索引查询排序（最左前缀原则）
- 联合索引以及单索引同时需求的时候考虑空间原则

#### 索引下推 （index condition pushdown ）简称ICP
- mysql5.6做的回表查询优化

在使用ICP的情况下，如果存在某些被索引的列的判断条件时，MySQL服务器将这一部分判断条件传递给存储引擎，
然后由存储引擎通过判断索引是否符合MySQL服务器传递的条件，只有当索引符合条件时才会将数据检索出来返回给MySQL服务器 。

索引条件下推优化可以减少存储引擎查询基础表的次数，也可以减少MySQL服务器从存储引擎接收数据的次数

#### 索引使用以及MySQL的慢SQL分析
- explain关键字

#### 索引失效问题（没用到）
- 不等于查询、列运算、like、全表扫描更快、联合索引顺序错误
- 函数计算
- - 破坏了有序性，优化器会放弃走树搜索功能，有可能选择遍历主键索引或者遍历普通索引
- 隐式类型转换
- - int和字符串类型对比会转int再比较
- 隐式字符编码转换
- - 同为字符串的按照数据长度增加方向进行转换(如 utf8--urf8mb4)
- - 关联查询中，如果解析后查询字段是utf8而给定的值是utf8mb4的，则会相当于在查询字段上加了转换函数
- - 查询字段是utf8mb4的，给的值是utf8，则类似于值上加函数，如此才能用上索引

#### 查询慢问题排查

##### 长时间不返回数据
- 等待MDL锁
- - show processlist找到持有MDL锁（ 显示状态为sleep）的进程并kill
- - 借助performance_schema和sys系统库
- - - （MySQL启动时需要设置performance_schema=on，相比off会有10%性能损失）
- - - select bloking_pid from sys.schema_table_lock_waits  可以直接找出造成阻塞的process id， 把这个连接⽤kill 命令断开即可
- 等待 flush
- - flush tables [t] with read lock; (t可以不加, 不加表示是flush所有表)
- 等 行锁
- - 读取数据要加读锁，如果有事务一直持有写锁并不提交，就会阻塞

##### 查询慢
- 一致性读
- - 查询时候遇到其他事务行锁重复大量更新单条记录，一致性读回查询undo log造成时间损耗
- 当前读
- - 带lock in share mode的SQL语句，是当前读，可以立即返回数据，不过这已经是更新后的数据

### 6.4 创建索引的要点

#### 创建索引注意
- 索引字段应该指定为NOT NULL，在MySQL中，含有空值的列很难进行查询优化，因为他们使得索引、索引的统计信息以及比较运算更加复杂
- 取值离散大的字段：
- 索引字段越小越好

#### 索引重建
- 删除数据库索引不一定会释放，需要定期重建优化
- 可以使用ALTER TABLE t engine=InnoDB的方式重建索引

### 6.5 排序功能

#### 按照线程分配 sort_buffer 内存

##### sort_buffer_size
- 如果sort_buffer_size小于要排序的数据量，则会利用磁盘临时文件辅助

##### 全字段排序
- 如果内存足够，就尽量多利用内存，mysql会优先选择全字段排序，不用重复回表取取数据

##### rowid排序
- max_length_for_sort_data 控制最长排序的⾏数据，如果mysql 认为单行太大，可能切换为rowid排序

#####  内存临时表
- 随机排序
- - mysql创建临时表，并使用 memory引擎
- - 扫描表从表中取出排序字段值，并用rand()函数生成一个大于0小于1的随机数，并把随机消暑和word分别存入临时表R和W字段
- - 按照R排序，初始化 sort_buffer，sort_buffer中有两个字段，一个double类型，一个整型
- - 从内存临时表中全表扫表，一行行取出R值和位置信息，分别存入sort_buffer中的两个字段
- - sort_buffer中根据R值排序，排序完成后，取出前三个结果的位置信息，依次从内存临时表中取出查询值并返回给客户端

##### tmp_table_size 配置
- 限制内存临时表的大小，如果临时表超过该值，那么内存临时表会转为磁盘临时表

##### 磁盘临时表
- 磁盘临时表默认引擎是 InnoDB
- 优先队列排序算法
- - MySQL 5.6版本引入的一个新的排序算法（临时文件算法是归并排序）
- - 需要维护的堆大小如果超出 sort_buffer_size的限制，则会进入磁盘排序，否则可以使用优先队列排序算法

#### 默认排序

##### 基础规则
- MySQL查询数据的时候，默认是按照获取数据的顺序排序
- 所以，在某些情况下，不加 order by 查询出来的数据可能是主观认为的乱序

##### 异常场景
- 如果一个表只有一个主键以及一个设置为索引的字段，我们查询 select *的时候，发现按照 非主键字段排序了
- explain分析结果显示，该语句走了非主键的索引覆盖查询，而不是主键全表扫描。默认使用了非主键的索引字段中读取出来的数据排序

### 6.6 主键自增

#### 自增值机制
- InnoDB引擎的⾃增值，其实是保存在了内存⾥，并且到了MySQL 8.0版本后，保存在redo log
- 从auto_increment_offset开始，以auto_increment_increment为步 ⻓，持续叠加，直到找到第⼀个⼤于X的值，作为新的⾃增值。
- 修改自增值处于插入流程中，数据传入并填充自增ID之后，实际插入数据之前，因此，在实际插入数据失败时，自增值已经变更，并不会回退
- 自增锁: 批量插入数据时会以依次递增的方式申请自增锁，从1开始，每次申请数量都是上次的两倍，如果遇到并发插入，就可能跳过已经存在的ID

#### 主键不连续情况
- 唯一键冲突
- 事务回滚
- 自增锁批量插入批量申请跳过已存在ID

## 7. 主从复制

### 7.1 主备复制流程
- 1. 在备库B上通过change master命令，设置主库A的IP、端⼝、⽤户名、密码，以及要从哪个 位置开始请求binlog，这个位置包含⽂件名和⽇志偏移量。
- 2. 在备库B上执⾏start slave命令，这时候备库会启动两个线程，就是图中的io_thread和 sql_thread。其中io_thread负责与主库建⽴连接。 
- 3. 主库A校验完⽤户名、密码后，开始按照备库B传过来的位置，从本地读取binlog，发给B。 
- 4. 备库B拿到binlog后，写到本地⽂件，称为中转⽇志（relay log）。 
- 5. sql_thread读取中转⽇志，解析出⽇志⾥的命令，并执⾏。 （后来由于多线程复制⽅案的引⼊，sql_thread演化成为了多个线程）

### 7.2 主备双M循环复制

#### binglog中记录的server id
- 1.规定两个库的server id必须不同，如果相同，则它们之间不能设定为主备关系； 
- 2.⼀个备库接到binlog并在重放的过程中，⽣成与原binlog的server id相同的新的binlog；
- 3.每个库在收到从⾃⼰的主库发过来的⽇志后，先判断server id，如果跟⾃⼰的相同，表示这 个⽇志是⾃⼰⽣成的，就直接丢弃这个⽇志

#### 其他循环复制场景

- 在⼀个主库更新事务后，⽤命令set global server_id=x修改了server_id
- 有三个节点的时候，trx1在节点 B执⾏的，因此binlog上的 server_id就是B，binlog传给节点 A，然后A和C搭建了双M结构，就会出现循环复制

#### 循环复制解决方案
(1)先执行如下命令
```
stop slave； 
CHANGE MASTER TO IGNORE_SERVER_IDS=(server_id_of_B); 
start slave; 
```
(2)一段时间后恢复serverid值
```
stop slave； 
CHANGE MASTER TO IGNORE_SERVER_IDS=(); 
start slave;
```

### 7.3 备库并行复制策略

#### MySQL版本5.6之后加入
- 支持粒度是按库并行，如果实例上是单库并不能应用到该策略

#### MariaDB的并行策略
- 1.在⼀组⾥⾯⼀起提交的事务，有⼀个相同的commit_id，下⼀组就是commit_id+1；（binglog同组落磁盘的组，不会修改同一行，不冲突）
- 2.commit_id直接写到binlog⾥⾯； 
- 3.传到备库应⽤的时候，相同commit_id的事务分发到多个worker执⾏； 
- 4.这⼀组全部执⾏完成后，coordinator再去取下⼀批。 

#### MySQL 5.7版本策略

- slave-parallel-type 来控制并⾏复制策略
- - 配置为DATABASE，表示使⽤MySQL 5.6版本的按库并⾏策略
- - 配置为 LOGICAL_CLOCK，表示的就是类似MariaDB的策略。不过，MySQL 5.7这个策 略，针对并⾏度做了优化
- 策略思想
- - 1.同时处于prepare状态的事务，在备库执⾏时是可以并⾏的；
- - 2.处于prepare状态的事务，与处于commit状态的事务之间，在备库执⾏时也是可以并⾏的。

##### 相关参数配置
- 1.binlog_group_commit_sync_delay参数，表示延迟多少微秒后才调⽤fsync; 
- 2.binlog_group_commit_sync_no_delay_count参数，表示累积多少次以后才调⽤fsync

这两个参数是⽤于故意拉⻓binlog从write到fsync的时间，以此减少binlog的写盘次数。
在 MySQL 5.7的并⾏复制策略⾥，它们可以⽤来制造更多的“同时处于prepare阶段的事务”。这样 就增加了备库复制的并⾏度

#### MySQL版本5.7.22的策略

- 基于 WRITESET的并⾏复制
- - 新增了⼀个参数binlog-transaction-dependency-tracking，⽤来控制是否启⽤这个新 策略。
- - 1.COMMIT_ORDER，表示 根据同时进⼊prepare和commit来判断是否可以并⾏的策略。 
- - 2.WRITESET，表示的是对于事务涉及更新的每⼀⾏，计算出这⼀⾏的hash值，组成集合 writeset。如果两个事务没有操作相同的⾏，也就是说它们的writeset没有交集，就可以并 ⾏。
- - 3.WRITESET_SESSION，是在WRITESET的基础上多了⼀个约束，即在主库上同⼀个线程先 后执⾏的两个事务，在备库执⾏的时候，要保证相同的先后顺序。

### 7.4 主备切换

#### 主从复制双M情况下 可靠性优先策略
- 1.判断备库B现在的seconds_behind_master，如果⼩于某个值（⽐如5秒）继续下⼀步，否 则持续重试这⼀步； 
- 2.把主库A改成只读状态，即把readonly设置为true； 
- 3.判断备库B的seconds_behind_master的值，直到这个值变成0为⽌； 
- 4.把备库B改成可读写状态，也就是把readonly 设置为false；
- 5.把业务请求切到备库B。 
- 这个切换流程，⼀般是由专⻔的HA系统来完成的，我们暂时称之为可靠性优先流程。（系统有不可用时间）

#### 主从复制双M情况下 可用性优先策略
- 直接切换， 把步骤4、5调整到最开始执行（系统可能数据不一致）
- 使用row格式的binlog时，数据不一致，问题更容易发现
- 一般情况下不建议使用该方案

#### 主库异常的判定方法
- 查表判断
- - 不完全准确 受到并发查询线程上限的影响（配置innodb_thread_concurrency参数，进入锁等待后，并发线程的计数会减一）
- 更新判断
- - 同样受并发线程上限影响，双M配置主备需要安排更新不同行
- 内部统计
- - file_summary_by_event_name表⾥统计了每次IO请求的时间

### 7.5 主备延迟

#### 产生原因与处理方案
- 备库机器性能低于主库（多备同机/硬件配置/参数配置不同等）
- - 备库采用双非1配置，可以略微降低IO压力
- - 理想来说应该 主备库选⽤相同规格的机器，并且做对称部署
- 备库压力大 ( 运营以及分析业务在备库执行导致 )
- - 采用一主多从的方式多机器提供读服务
- - 通过binglog输出到外部系统，通过外部系统如hadoop等来提供统计查询能力
- 大事务（如一次性大批删除、大表DDL）
- - 小批量轮番删除
- - 计划内DDL、新建临时表同步数据过去，追上了再切换
- - 主库DML语句并发⼤,从库qps⾼ ；、从库上在进⾏备份操作 、设置的是延迟备库 、备库空间不⾜的情况下 
- 表上⽆主键的情况(主库利⽤索引更改数据,备库回放只能⽤全表扫描,这种情况可以调整slave_rows_search_algorithms参数适当优化下) 

#### 主从延时过长业务解决方案
- 强制读取主库
- - 业务可以忍受的情况下忽略
- - 一般会伴随一个负责管理后端的组建，比如 Zookeeper
- sleep方案
- - 延时一段时间后再查询写入的信息，也可以将该方案做在业务前端
- 选择性读取主库
- - 加中间件层：维护一个写请求的key，读取的时候存在则走此处，一定时间后删除
- - 加缓存层： 维护一个写请求的key，失效时长主从延迟时长，读取的时候存在则路由到主库
- 分库、打开从库的并行复制

## 8. 高可用架构

### 8.1 一主多从的主备切换

#### 基于位点的主备切换（主库故障T时刻的binlog位点），需要跳过错误

#### GTID  ( 5.6版本引入 )

- GTID的全称是Global Transaction Identififier，也就是全局事务ID，是⼀个事务在提交的时候⽣ 成的，是这个事务的唯⼀标识
- 官方定义 GTID=source_id:transaction_id,  可以理解为GTID=server_uuid:gno
- server_uuid是⼀个实例第⼀次启动时⾃动⽣成的，是⼀个全局唯⼀的值； gno是⼀个整数，初始值是1，每次提交事务的时候分配给这个事务，并加1。
- 加上参数 gtid_mode=on和enforce_gtid_consistency=on启动mysql实例就可以开启GTID模式

#### 基于GTID的主备切换
- 实例B指定主库A'，基于主备协议建立连接，并把 GTID集合set_b发给A'，
- 实例A'算出set_a与set_b的差集，在set_a而不在set_b的GTID集合，判断A'的本地是否包含了这个差集需要的所有binlog事务
- - 如果不包含，表示A'已经删除B需要的binlog，直接返回错误
- - 如果全包含，A'从自己binlog中，找出第一个不在 set_b的事务，发给B
- 之后就从这个事务开始，往后读文件，按顺序取binlog发给B去执行 

#### GTID和在线DDL

- 双M模式的在线DDL
- - 实际从库 stop slave，而后从库执行DDL，查出GTID并在主库提交一条该GTID的空事务，跳过复制流程。执行主备切换后再来一遍

### 8.2 数据误删处理（重在预防）

#### 误删行数据
- Flashback工具解析binlog
- 线上数据不做删除，所有业务数据伪删除，除非归档

#### 误删库/表
- 定期全量备份，实时备份binlog，恢复时跳过误删的记录，备份恢复功能定期演练
- 延迟复制备库 

#### 预防误删库/表
- 账号分离
- - 只读权限，收紧权限
- 制定操作规范
- - 先改名，后删除，只能删除固定格式名称的表等

## 9. 维护处理

### 9.1 kill相关知识

#### kill的方式
- 结束某个线程   kill query thread_id 
- 断开线程连接   kill connection thread_id

#### kill延时
- 如果执行kill之后线程没有立即退出, 因为线程没有执行到判断线程状态的逻辑；或者终止逻辑耗时较长

### 9.2 内存相关

#### 全表扫描对server 层的影响

- 数据取发流程是 读取然后经过net_buffer批量轮流发送的

#### buffer pool
- 数据页维护在内存buffer pool中还可以加速查询， 查询加速效果的重要指标: 内存命中率
- InnoDB Buffer Pool的⼤⼩是由参数 innodb_buffer_pool_size确定的，⼀般建议设置成可⽤物 理内存的60%~80%。
- InnoDB内存管理⽤的是最近最少使⽤ (Least Recently Used, LRU)算法，这个算法的核⼼就是淘汰最久未使⽤的数据。
- 优化LRU淘汰算法，通过链表实现（ 5/3 青老区域 ），针对全表扫描做了优化

## 10. join查询

### 10.1 join查询类型

#### 交叉连接 CROSS JOIN
- 交叉连接(笛卡尔积)
- select r.*,s.* from r,s

#### 内连接 INNER JOIN
- 等值连接：ON A.id=B.id
- 不等值连接：ON A.id > B.id
- 自连接：SELECT * FROM A T1 INNER JOIN A T2 ON T1.id=T2.pid

#### 左外连接 LEFT JOIN 
- LEFT OUTER JOIN, 以左表为主，先查询出左表，按照ON后的关联条件匹配右表，没有匹配到的用NULL填充，可以简写成LEFT JOIN

#### 右外连接 RIGHT JOIN
- RIGHT OUTER JOIN, 以右表为主，先查询出右表，按照ON后的关联条件匹配左表，没有匹配到的用NULL填充，可以简写成RIGHT JOIN

#### 联合查询（UNION与UNION ALL）
- 就是把多个结果集集中在一起，UNION前的结果为基准，需要注意的是联合查询的列数要相等，相同的记录行会合并
- UNION 操作会对结果去重且排序，所以从速度来说， UNION ALL会更胜一筹
- 如果使用UNION ALL，不会合并重复的记录行
- 效率 UNION ALL  高于 UNION

#### 全连接（FULL JOIN）
- MySQL不支持全连接
- 可以使用LEFT JOIN 和UNION和RIGHT JOIN联合使用

### 10.2 join查询流程

#### Index Nested-Loop Join，简称NLJ
- 从驱动表查询一行数据R，提取关联字段值，再去被驱动表索引查询满足条件的数据，跟R组成一行，作为结果集合的一部分。如此重复步骤循环
- 这种情况可以利用到被驱动表的索引，适合小表做驱动表，时间复杂度会好点

#### Simple Nested-Loop Join，MySQL也不用
- 驱动表自索引查询一行数据R，主键取数据，再查询被驱动表（无索引，全表扫描），跟R组成行数据。循环其他行

#### Block Nested-Loop Join，简称BNL
- 1.把表t1的数据读⼊线程内存join_buffer中，由于我们这个语句中写的是select *，因此是把整 个表t1放⼊了内存；（如果jion_buffer放不下，可以分段放）
- 2.扫描表t2，把表t2中的每⼀⾏取出来，跟join_buffer中的数据做对⽐，满⾜join条件的，作 为结果集的⼀部分返回。
- 与简单jion复杂度一样，但是内存操作节省磁盘io操作，join_buffer_size 越大效果越好

#### 小表的确定
- 在决定哪个表做驱动表的时候，应该是两个表按照各⾃的条件过滤，过滤完 成之后，计算参与join的各个字段的总数据量，数据量⼩的那个表，就是“⼩表”，应该作为驱动 表

### 10.3 join语句优化

#### Multi-Range Read优化 (MRR)
- 这个优化的目的是尽量使用顺序读盘（回表是单行查询，一般情况主键递增的数据是顺序写入磁盘的，这样区间查询比较接近顺序读，能够提升读性能）
- 根据索引a定位满足条件的记录，将id值放入read_rnd_buffer中，并对id进行性递增排序，之后在一次到主键ID的索引汇总查记录并返回结果（read_rnd_buffer_size参数控制空间大小）

#### Batched Key Acess(BKA)算法
- MySQL5.6版本引入
- - 使用BKA依赖MRR，需要先设置 set optimizer_switch='mrr=on,mrr_cost_based=off,batched_key_access=on';
- NLJ使用该方法优化，积累获取的驱动表ID，再批量获取被驱动表数据
- BNL优化，可以尝试在被驱动表加索引转换为BKA算法，如果不适合，则可以提取满足条件的被驱动表数据组建临时表，给查询关联字段加上临时索引，触发BKA算法

#### 扩展-hash join，MySQL的优化器和执行器不支持
- 可以考虑业务层做hash结构的比对
- MySQL8.0做了相关支持

## 11. 临时表相关

### 11.1 临时表特性

- 1.建表语法是create temporary table …。
- 2.⼀个临时表只能被创建它的session访问，对其他线程不可⻅。所以，图中session A创建的 临时表t，对于session B就是不可⻅的。 
- 3.临时表可以与普通表同名。
- 4.session A内有同名的临时表和普通表的时候，show create语句，以及增删改查语句访问的 是临时表

### 11.2 临时表与binlog
- 只在binlog_format=statment/mixed 的时候，binlog中才会记录临时表的操 作。
- MySQL在记录binlog的时候，会把主库执⾏这个语句的线程id写到binlog中。这样，在备库的应 ⽤线程就能够知道执⾏每个语句的主库线程id，并利⽤这个线程id来构造临时表的 table_def_key

### 11.3 临时表的应⽤
- 临时存储查询数据
- 分库分表时候用临时表来汇总排序

### 11.4 group by 优化
- 1.如果对group by语句的结果没有排序要求，要在语句后⾯加 order by null；
- 2.尽量让group by过程⽤上表的索引，确认⽅法是explain结果⾥没有Using temporary 和 Using filesort；
- 3.如果group by需要统计的数据量不⼤，尽量只使⽤内存临时表；也可以通过适当调⼤ tmp_table_size参数，来避免⽤到磁盘临时表； 
- 4.如果数据量实在太⼤，使⽤SQL_BIG_RESULT这个提示，来告诉优化器直接使⽤排序算法 得到group by的结果。

## 12. 数据库引擎

### 12.1 innoDB
以上大部分内容都是基于InnoDB的，这里不多说

#### innoDB分区表
- 分区表跟⽤户分表⽐起来，有两个绕不开的问题：⼀个是第⼀次访问的时候需要访问所有分区，另⼀个是共⽤MDL锁。
- 如果要使⽤分区表，就不要创建太多的分区。
- 怎么给分区表t创建⾃增主键。由于MySQL要求主键包含所有的分区字段，所以 肯定是要创建联合主键的

### 12.2 Memory

#### 内存表索引
- 使用hash索引， 索引与数据分开存放
- 可以使用 alter table t1 add index a_btree_index using btree (id);的方式加 Btree索引

#### 内存表的锁
- 不支持行锁，只支持表锁

#### 特性
- 数据存放在内存中，如果机器重启，数据表结构与数据都会丢失
- 在数据库重启之后，MySQL会往binlog⾥⾯写⼊⼀⾏DELETE FROM t1，来删除内存表，这样的话，主备复制的备库内存表也会被清除
- 内存表在生产环境几乎不用

#### 与InnoDB的区别
- 1.InnoDB表的数据总是有序存放的，⽽内存表的数据就是按照写⼊顺序存放的；
- 2.当数据⽂件有空洞的时候，InnoDB表在插⼊新数据的时候，为了保证数据有序性，只能在固定的位置写⼊新值，⽽内存表找到空位就可以插⼊新值；
- 3.数据位置发⽣变化的时候，InnoDB表只需要修改主键索引，⽽内存表需要修改所有索引； 
- 4.InnoDB表⽤主键索引查询时需要⾛⼀次索引查找，⽤普通索引查询的时候，需要⾛两次索引 查找。⽽内存表没有这个区别，所有索引的“地位”都是相同的。
- 5.InnoDB⽀持变⻓数据类型，不同记录的⻓度可能不同；内存表不⽀持Blob 和 Text字段，并且即使定义了varchar(N)，实际也当作char(N)，也就是固定⻓度字符串来存储，因此内存表 的每⾏数据⻓度相同。

## 13. 如何快速复制表

### 13.1 mysqldump⽅法导出到临时文件

#### 命令与参数解析
- mysqldump -h$host -P$port -u$user --add-locks --no-create-info --single-transaction --no-create-info --set-gtid-purged --result-file
- 如此得到的数据是组织好的 insert 语句。另外mysqldump提供了⼀个–tab参数，可以同时导出表结构定义⽂件和csv数据⽂件。
- 1.–single-transaction的作⽤是，在导出数据的时候不需要对表db1.t加表锁，⽽是使⽤ START TRANSACTION WITH CONSISTENT SNAPSHOT的⽅法；
- 2.–add-locks设置为0，表示在输出的⽂件结果⾥，不增加" LOCK TABLES t WRITE;" ；
- 3.–no-create-info的意思是，不需要导出表结构；
- 4.–set-gtid-purged=off表示的是，不输出跟GTID相关的信息；
- 5.–result-file指定了输出⽂件的路径，其中client表示⽣成的⽂件是在客户端机器上的。

### 13.2 导出CSV文件

#### 导出到服务端本地
##### 命令与规则
- select * from db1.t where a>900 into outfile '/server_tmp/t.csv';
- select …into outfifile⽅法不会⽣成表结构⽂件, 所以我们导数据时还需要单 独的命令得到表结构定义
- 1.这条语句会将结果保存在服务端
- 2.into outfile指定了⽂件的⽣成位置（/server_tmp/），这个位置必须受参数secure_file_priv 的限制
- 3.这条命令不会帮你覆盖⽂件, 如果存在同名你文件执行会报错
- 4.这条命令⽣成的⽂本⽂件中，原则上⼀个数据⾏对应⽂本⽂件的⼀⾏。数据中的换⾏符、制表符这类符号，前⾯都会跟上“\”这个转义符

#### 将服务端本地csv文件倒入库中
##### 命令与规则
- load data infile '/server_tmp/t.csv' into table db2.t;
- 主库binlog格式为statement时，除了记录该行命令，还会将文件写入binlog
- 执行命令的时候如果 是 local file，则加载客户端本地文件数据，如果不带 local关键字，则会读取服务端文件

### 13.3 物理拷贝

#### 基础解释

##### 直接拷贝数据文件无效
- ⼀个InnoDB表，除了包含这两个物理⽂件外，还需要在数据字典中注册。
- 直接拷⻉这两 个⽂件的话，因为数据字典中没有db2.t这个表，系统是不会识别和接受它们的。

#### 具体操作方法

##### 导出方法
- 在MySQL 5.6版本引⼊了可传输表空间(transportable tablespace)的⽅法，可以通过导出+导⼊表空间的⽅式，实现物理拷⻉表的功能

##### 导出流程
- 1.执⾏ create table r like t，创建⼀个相同表结构的空表；
- 2.执⾏alter table r discard tablespace，这时候r.ibd⽂件会被删除； 
- 3. 执⾏flush table t for export，这时候db1⽬录下会⽣成⼀个t.cfg⽂件； 
- 4. 在db1⽬录下执⾏cp t.cfg r.cfg; cp t.ibd r.ibd；这两个命令；
- 5. 执⾏unlock tables，这时候t.cfg⽂件会被删除； 
- 6. 执⾏alter table r import tablespace，将这个r.ibd⽂件作为表r的新的表空间，由于这个⽂ 件的数据内容和t.ibd是相同的，所以表r中就有了和表t相同的数据。

### 13.4 xtranbackup

#### 介绍
- 100G 以上的库，可以考虑用 xtranbackup 来做，备份速度明显要比 mysqldump 要快
- 一般是选择一周一个全备，其余每天进行增量备份，备份时间为业务低峰期

#### 备份原理
- xtrabackup 属于物理备份，直接拷贝表空间文件，同时不断扫描产生的 redo 日志并保存下来



## 14. 分库分表

### 14.1 分库分表瓶颈条件

#### I/O瓶颈
- 第一种：磁盘读IO瓶颈，热点数据太多，数据库缓存放不下，每次查询会产生大量的IO，降低查询速度->分库和垂直分表
- 第二种：网络IO瓶颈，请求的数据太多，网络带宽不够 ->分库

#### CPU瓶颈
- 第一种：SQL问题：如SQL中包含join,group by, order by，非索引字段条件查询等，增加CPU运算的操作->SQL优化，建立合适的索引，在业务Service层进行业务计算。
- 第二种：单表数据量太大，查询时扫描的行太多，SQl效率低，增加CPU运算的操作。->水平分表。

#### 拆分条件
- 分库分表之前，先尽力做力所能及的优化：升级硬件、升级网络、读写分离、索引优化，归档处理等。当数据量达到单表瓶颈后，在考虑分库分表。
- 能不分就不分
- 数据量过大，正常运维影响业务访问（DDL锁表影响业务的时候）
- 随着业务发展，需要对某些字段垂直拆分
- 数据量快速增长

### 14.2 拆分方式与中间件

#### 分库分表中间件（ Sharding-jdbc Mycat）

#### 拆分方式

- 水平拆分
- - 保持数据表结构不变，通过某种策略存储数据分片
- - 这样每一片数据分散到不同的表或者库中，达到了分布式的目的
- - 水平拆分可以支撑非常大的数据量
- - 但 分片事务难以解决 ，跨界点Join性能较差，逻辑复杂
- 垂直拆分
- - 可以使得行数据变小，在查询时减少读取的Block数，减少I/O次数
- - 垂直分区可以简化表的结构，易于维护
- - 主键会出现冗余，需要管理冗余列，并会引起Join操作，可以通过在应用层进行Join来解决
- - 垂直分区会让事务变得更加复杂

#### 动态扩容
- 一次性分足库表 32*32=1024
- 倍数增加机器 / 切换路由规则

#### 全局唯一ID生成机制
- 基于单库的自增id
- snowflake算法  时间戳-机房ID-机器ID-增长序列

### 14.3 分库分表后的问题

#### 事务一致性问题
- 分布式事务、最终一致性方案等等

#### 跨节点关联查询join问题解决
- 使用全局表（通用依赖的表每个库都存一份）
- 字段冗余（反范式冗余部分数据）
- 数据组装（代码层面查询组装数据）
- ER分片（将关联数据路由到相同分片存储，适应后续使用）

#### 跨节点分页、排序、函数问题
- 多分片数据统计性能问题（类ES）

#### 拆分迁移方案（扩容与迁移）
- 停机维护
- 双写迁移


## 15. 参考资料
- 《MySQL实战45讲》
- 《深入浅出MySQL》
- 《高性能MySQL》
