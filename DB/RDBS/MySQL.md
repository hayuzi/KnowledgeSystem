# MySQL 数据库

## 数据表设计

### 三大范式

- 第一范式（原子性）
- - 数据表中每列必须是不可拆分的最小单元
- 第二范式（唯一性）
- - 非主键列完全依赖于主键,而不能是依赖于主键的一部分
- 第三范式（独立性）
- - 非主键列只依赖于主键,不依赖于其他非主键

### 其他思考

- 主键自增
- - 如果不设置主键，InnoDB会选择一个唯一键作为主键、如果没有唯一键，会生成一个隐式主键
- 字段not null
- - null会占用更多字节，且在程序中造成很多和预期不符合的情况

## 数据类型问题

- char、varchar
- - varchar(10)的10代表了申请的空间长度，可是可以存储的数据的最大长度
- int
- - int(10)的10代表了展示长度，不足10位的以0填充
- -  也就是说int(1)和int(10)能存储的数字大小以及空间占用相同，知识展示时候按照长度展示

## redo log以及binlog

### - WAL（Write Ahead Logging）

#### 先写日志（redolog）再写磁盘不忙时候再写账本

#### binlog是server层的日志（归档日志），binlog日志是逻辑日志、binlog日志可以追加写入

#### redo log是InnoDB引擎特有的，redo log 是物理日志，redo log是循环写的，空间固定会⽤完

### binlog三种格式

#### statement

##### statement模式下,记录单元为语句

##### 由于sql的执行是有上下文的,因此在保存的时候需要保存相关的信息

##### 同时还有一些使用了函数之类的语句无法被记录复制

#### row

##### row级别下,记录单元为每一行的改动，基本是可以全部记下来

##### 由于很多操作,会导致大量行的改动(比如alter table),因此这种模式的文件保存的信息太多,日志量太大

##### 新版的MySQL中对row级别也做了一些优化,当表结构发生变化的时候,会记录语句而不是逐行记录.

#### mixed

##### 一种折中的方案,普通操作使用statement记录,当无法使用statement的时候使用row

### binglog写入机制

#### 事务执行过程中写到binlog cahce，事务提交时候，再把binlog cache写到binlog文件

#### twrite 和fsync的时机，是由参数sync_binlog控制

##### write指的就是指把⽇志写⼊到⽂件系统的page cache

##### 每个线程都有自己的binlog cache 但是共用一份binlog

#### sync_binlog配置

##### 0表示每次提交事务都只weite不fsync

##### 1表示每次提交事务都会fsync

##### N（N>1），表示每次提交事务都write，但积累N个事务后才fsync

### redolog写入机制

#### 事务执行过程中，先写入redo log buffer

#### redo log三种状态

##### 存在 redo log buffer内存中，物理上是在 mysql进程内存中

##### 写到磁盘write 但是没有持久化fsync，物理上是在文件系统的page_chage

##### 持久化到磁盘，对应的是hard disk

##### InnoDB有⼀个后台线程，每隔1秒，就会把redo log buffffer中的⽇志，调⽤write写到⽂件系统的
page cache，然后调⽤fsync持久化到磁盘。一个没提交的事务的redo log也可能已经持久化到磁盘了

#### innodb_flush_log_at_trx_commit参数

##### 0 表示每次事务提交都只把redo log留在redo log buffer中

##### 1 表示每次事务提交都把 relo log直接持久化到磁盘

##### 2 表示每次事务提交时都只是把 redo log 写到page cache

#### sync_binlog 与 innodb_flush_log_at_trx_commit参数 双1配置

##### 正常线上推荐双1配置

##### 非双1场景

###### 业务高峰期、备库复制延迟、⽤备份恢复主库的副本、批量导入数据

###### ⼀般情况下，把⽣产库改成“⾮双1”配置，是设置innodb_flflush_logs_at_trx_commit=2、
sync_binlog=1000。

### 日志逻辑许序列号与组提交

#### 日志逻辑许序列号 log sequence number ， LSN

##### LSN单调递增，对应redo_log的一个个写入点，每次写入长度为lenght的redo log，LSN的值就会加上length

##### LSN也会写到InnoDB的数据⻚中，来确保数据⻚不会被多次执⾏重复的redo log

#### 组提交（group commit）

##### 多事务时，leader事务提交写盘的时候会带LSN，将LSN低于写入值的都此久化到次磁盘，这时候其他相关事务就可以直接返回不需要重复操作

### 更新两阶段提交

#### 更新流程

##### 1. 取id=1的行，在内存直接返回，不在则从磁盘读入内存 

##### 2. 将行的c字段值加1，写入新行， 新行更新到内存

##### 3. 写入redo log，处于prepare阶段

##### 4. 写binlog

##### 5. 提交事务，处于commit状态

#### 崩溃恢复

##### 处于3-4阶段崩溃，恢复之后会回滚

##### 处于4-5阶段崩溃

###### 恢复之后会如果redo log里事务是完成的，则直接提交；

###### 如果redo log里的事务只有完成的prepare，则通过binlog记录判断是回滚还是提交

###### binlog有完整格式

####### redo log和 binlog有共同的数据字段 XID

## sql运行原理

### 执行过程

#### 客户端--连接器--(查询缓存)--分析器--优化器--执行器-存储引擎

### Server层

#### 连接器

##### 管理连接以及权限验证

#### 查询缓存

##### 命中则直接返回结果

##### MySQL 8.0开始删除了查询缓存功能

#### 分析器

##### 词法分析，语法分析

###### 列不存在也会在此处报错

#### 优化器

##### 执行计划生成、索引选择

#### 执行器

##### 也会验证个表T有没有执⾏查询的权限

##### 操作引擎，返回结果

### 存储引擎

#### 存储数据、提供读写接口

##### InnoDB

###### 支持事务、行级别锁、MVCC、外键

##### MyISAM、Memory、Archive等等

## 数据库事务

### 特性

#### ACID特性

##### A=Atomicity 原子性

###### 要么全部成功、要么全部失败

##### C=Consistency 一致性

###### 系统(数据库)总是从一个一致性的状态转移到另一个一致性的状态,不会存在中间状态

##### I=Isolation 隔离性

######  通常来说:一个事务在完全提交之前,对其他事务是不可见的

##### D=Durability 持久性

###### 一旦事务提交,那么就永远是这样子了,哪怕系统崩溃也不会影响到这个事务的结果

### 多事务并行有问题

#### 脏读、不可重复度、幻读问题

### 隔离级别

#### 未提交读

##### 其他事务可以看到本事务没有提交的部分修改，有脏读问题（其他事务可能回滚，看到的数据则不准确）

#### 已提交读

##### 其他事务只能读取到本事务已经提交的部分，有不可重复读问题

###### 不可重复读重点是修改，同一个事务中再次读取发现值不同

###### 为了解决数据和日志不一样问题，可以使用该隔离级别加binlog格式设置为row

#### 可重复读

##### 事务涉及行进行行锁，有幻读问题

###### 幻读的重点在与新增，其他事务新增导致本事务查询数据多出来了

###### InnoBD索引默认使用该隔离级别

##### InnoDB用间隙锁解决幻读问题(Gap Lock)

###### 跟间隙锁存在冲突关系的，是 "往这个间隙中插⼊⼀个记录" 这个操作

###### 间隙锁和⾏锁合称next-key lock，每个next-key lock都是前开后闭区间

##### innodb自动使用间隙锁的条件

###### 间隙锁只在可重复读的隔离级别下存在 

###### 检索条件必须有索引（没有索引的话，mysql会全表扫描，那样会锁定整张表所有的记录，包括不存在的记录，此时其他事务不能修改不能删除不能添加）

##### 间隙锁加锁规则

###### 原则一 枷锁基本单位是next-key lock

###### 原则二 查找过程中访问到的对象才会加锁

###### 优化一  索引上的等值查询，给唯⼀索引加锁的时候，next-key lock退化为⾏锁；

###### 优化二 索引上的等值查询，向右遍历时且最后⼀个值不满⾜等值条件的时候，next-key lock退化为间隙锁

###### ⼀个bug：唯⼀索引上的范围查询会访问到不满⾜条件的第⼀个值为⽌

#### 可串行化

##### 强制串行执行，并发性能会极速下降

### MVCC多版本并发控制

#### 锁机制

##### 根据读写

###### 排他锁（读锁，可以加多个）

###### 共享锁（写锁，只可以加一个）

##### 根据锁范围

###### 全局锁

####### 全局锁的典型使⽤场景是，做全库逻辑备份

####### 命令:  Flush tables with read lock (FTWRL)

###### 表级别锁

####### 表锁和元数据锁(MDL)

######## 访问表的时候会自动 MDL（保证读写正确性）

######## 逻辑备份时候遇到binlog的DDL语句后流程

####### online DDL

######## 三种方式以及坑

###### 行级别锁

####### 两阶段锁协议

######## InnoDB 行锁在需要的时候才加，等事务结束才释放

######## 业务处理时候： 如果事务要锁多行，要把最可能造成冲突与影响并发的锁今后后置

###### 死锁和死锁检测

####### 死锁解决

######## 等待与超时

######### InnoDB的innodb_lock_wait_timeout默认配置是 50s

######## 主动检测与回滚

######### 热点行更新导致死锁、 死锁检测耗费大量的cpu资源

######### 临时关闭死锁检测(极度不推荐)、控制并发度

######### 业务设计上拆解热点行为多条记录

##### InnoDB实现了行锁、页锁、表锁

#### InnoDB的MVCC

##### 是通过在每行纪录后面保存两个隐藏的列来实现的

##### 隐藏列保存行的创建版本号以及过期（删除）版本号

###### 每次更新都会记录回滚操作

###### 回滚日志在不需要的时候会删除

###### 回滚日志影响长事务效率

##### 每开始一个新的事务，系统版本号都会自动递增

##### 快照读 / 当前读

###### 快照读（搜索时时候不会加锁）

####### 一般的 select * from ... where ...  查询语句都是快照读

###### 当前读（会在搜索的时候加锁）

#######  select * from ... where ... for update

####### elect * from .... where ... lock in share mode

####### update .... set .. where ...  与 delete from. . where ..

##### undo log以及redo log

##### MVCC流程

###### 开始事务

###### 记录数据行数据到undo log（未考虑redo log）

###### 更新数据

###### undo log写到磁盘

###### 将数据写入磁盘

###### 提交事务

### 事务启动方式

#### 显式声明 begain commit

#### set autocommit=0

## 索引原理

### B+树

#### 基于多路平衡查找树

##### 专门为了外存储设备设计的

##### 磁盘读取以块为单位，同块数据会一次性读取

##### 存储引擎页概念（磁盘管理的最小单位）、InnoDB引擎默认每个页大小为16k

##### 每个多路平衡查找树的节点占用一个磁盘块或页空间，可以减少IO次数

##### 节点数据页的分页与合并

##### InnoDB存储引擎设计时根节点常驻内存

#### 叶子结点存记录

##### 聚簇索引

###### InnoDB引擎的主键索引，叶子节点存数据记录

##### 非聚簇索引

###### 其他索引，叶子节点存主键

#### 扩展知识（B*树）

##### B*树是B+树的变体，在B+树的非根和非叶子结点再增加指向兄弟的指针；

##### B*树定义了非叶子结点关键字个数至少为(2/3)*M，即块的最低使用率为2/3（代替B+树的1/2）。

##### MySQL未使用该组织方式

###### 但是每条数据的插入与删除都会影响到多层级节点的前后指针，这会有一部分管理难度 以及 性能消耗

#### MySQL8.0 引入函数索引

##### 内部是依据虚拟列来实现的

###### 虚拟列不存储在数据行中，但虚拟列的元数据信息会存在于相关系统表中，对虚拟列的添加或者删除只会涉及这些系统表，不会导致数据表的重建，所以效率很高

###### 需要注意，不能建立虚拟列和真实列的联合索引

### Hash索引，InnoDB不用

#### Hash表

##### 不适合做范围查询，而且数据不一定均衡

### 表索引优化与分析

#### 索引覆盖查询

##### 非索引覆盖会再次回表查询提取数据

#### 创建索引考虑的因素

##### 常用来查询排序的字段、且区分度别叫大的

##### 联合索引查询排序（最左前缀原则）

##### 联合索引以及单索引同时需求的时候考虑空间原则

#### 索引下推

##### mysql5.6做的回表查询优化

#### 索引使用以及MySQL的慢SQL分析

##### explain关键字

#### 索引失效问题（没用到）

##### 不等于查询、列运算、like、全表扫描更快、联合索引顺序错误

##### 函数计算

###### 破坏了有序性，优化器会放弃走树搜索功能，有可能选择遍历主键索引或者遍历普通索引

##### 隐式类型转换

###### int和字符串类型对比会转int再比较

##### 隐式字符编码转换

###### 同为字符串的按照数据长度增加方向进行转换(如 utf8--urf8mb4)

###### 关联查询中，如果解析后查询字段是utf8而给定的值是utf8mb4的，则会相当于在查询字段上加了转换函数

###### 查询字段是utf8mb4的，给的值是utf8，则类似于值上加函数，如此才能用上索引

#### 查询慢问题排查

##### 长时间不返回数据

###### 等待MDL锁

####### show processlist找到持有MDL锁（ 显示状态为sleep）的进程并kill

####### 借助performance_schema和sys系统库

######## （MySQL启动时需要设置performance_schema=on，相比off会有10%性能损失）

######## select bloking_pid from sys.schema_table_lock_waits  可以直接找出造成阻塞的process id， 把这个连接⽤kill 命令断开即可

###### 等待 flush

####### flush tables [t] with read lock; (t可以不加, 不加表示是flush所有表)

###### 等  行锁

####### 读取数据要加读锁，如果有事务一直持有写锁并不提交，就会阻塞

##### 查询慢

###### 一致性读

####### 查询时候遇到其他事务行锁重复大量更新单条记录，一致性读回查询undo log造成时间损耗

###### 当前读

####### 带lock in share mode的SQL语句，是当前读，可以立即返回数据，不过这已经是更新后的数据

### 索引重建

#### 删除数据库索引不一定会释放，需要定期重建优化

#### 可以使用ALTER TABLE t engine=InnoDB的方式重建索引

### 排序功能

#### 按照线程分配 sort_buffer 内存

##### 如果sort_buffer_size小于要排序的数据量，则会利用磁盘临时文件辅助

##### 全字段排序

###### 如果内存足够，就尽量多利用内存，mysql会优先选择全字段排序，不用重复回表取取数据

##### rowid排序

###### max_length_for_sort_data 控制最长排序的⾏数据，如果mysql 认为单行太大，可能切换为rowid排序

##### 内存临时表

###### 随机排序

####### mysql创建临时表，并使用 memory引擎

####### 扫描表从表中取出排序字段值，并用rand()函数生成一个大于0小于1的随机数，并把随机消暑和word分别存入临时表R和W字段

####### 按照R排序，初始化 sort_buffer，sort_buffer中有两个字段，一个double类型，一个整型

####### 从内存临时表中全表扫表，一行行取出R值和位置信息，分别存入sort_buffer中的两个字段

####### sort_buffer中根据R值排序，排序完成后，取出前三个结果的位置信息，依次从内存临时表中取出查询值并返回给客户端

###### tmp_table_size 配置

####### 限制内存临时表的大小，如果临时表超过该值，那么内存临时表会转为磁盘临时表

##### 磁盘临时表

###### 磁盘临时表默认引擎是 InnoDB

###### 优先队列排序算法

####### MySQL 5.6版本引入的一个新的排序算法（临时文件算法是归并排序）

####### 需要维护的堆大小如果超出 sort_buffer_size的限制，则会进入磁盘排序，否则可以使用优先队列排序算法

### 主键自增

#### 自增值机制

##### InnoDB引擎的⾃增值，其实是保存在了内存⾥，并且到了MySQL 8.0版本后，保存在redo log

##### 从auto_increment_offset开始，以auto_increment_increment为步 ⻓，持续叠加，直到找到第⼀个⼤于X的值，作为新的⾃增值。

##### 修改自增值处于插入流程中，数据传入并填充自增ID之后，实际插入数据之前，因此，在实际插入数据失败时，自增值已经变更，并不会回退

##### 自增锁     批量插入数据时会以依次递增的方式申请自增锁，从1开始，每次申请数量都是上次的两倍，如果遇到并发插入，就可能跳过已经存在的ID

#### 主键不连续情况

##### 唯一键冲突

##### 事务回滚

##### 自增锁批量插入批量申请跳过已存在ID

## 主从复制

### 主备复制流程

#### 1. 在备库B上通过change master命令，设置主库A的IP、端⼝、⽤户名、密码，以及要从哪个 位置开始请求binlog，这个位置包含⽂件名和⽇志偏移量。

#### 2. 在备库B上执⾏start slave命令，这时候备库会启动两个线程，就是图中的io_thread和 
sql_thread。其中io_thread负责与主库建⽴连接。

#### 3. 主库A校验完⽤户名、密码后，开始按照备库B传过来的位置，从本地读取binlog，发给B。 

#### 4. 备库B拿到binlog后，写到本地⽂件，称为中转⽇志（relay log）。 

#### 5. sql_thread读取中转⽇志，解析出⽇志⾥的命令，并执⾏。 （后来由于多线程复制⽅案的引⼊，sql_thread演化成为了多个线程）

### 主备双M循环复制

#### binglog中记录的server id

##### 1. 规定两个库的server id必须不同，如果相同，则它们之间不能设定为主备关系；

##### 2. ⼀个备库接到binlog并在重放的过程中，⽣成与原binlog的server id相同的新的binlog；

##### 3. 每个库在收到从⾃⼰的主库发过来的⽇志后，先判断server id，如果跟⾃⼰的相同，表示这 
个⽇志是⾃⼰⽣成的，就直接丢弃这个⽇志

#### 其他循环复制场景

##### 在⼀个主库更新事务后，⽤命令set global server_id=x修改了server_id

##### 有三个节点的时候，trx1在节点 B执⾏的，因此binlog上的
server_id就是B，binlog传给节点 A，然后A和C搭建了双M结构，就会出现循环复制

#### 循环复制解决方案

##### 1. 先执行如下命令

###### stop slave； 
CHANGE MASTER TO IGNORE_SERVER_IDS=(server_id_of_B);
start slave;

##### 2. 一段时间后恢复serverid值

###### stop slave；
CHANGE MASTER TO IGNORE_SERVER_IDS=();
start slave;

### 备库并行复制策略

#### MySQL版本5.6之后加入

##### 支持粒度是按库并行，如果实例上是单库并不能应用到该策略

#### MariaDB的并行策略

##### 1. 在⼀组⾥⾯⼀起提交的事务，有⼀个相同的commit_id，下⼀组就是commit_id+1；（binglog同组落磁盘的组，不会修改同一行，不冲突）

##### 2. commit_id直接写到binlog⾥⾯； 

##### 3. 传到备库应⽤的时候，相同commit_id的事务分发到多个worker执⾏； 

##### 4. 这⼀组全部执⾏完成后，coordinator再去取下⼀批。 

#### MySQL 5.7版本策略

##### slave-parallel-type 来控制并⾏复制策略

###### 配置为DATABASE，表示使⽤MySQL 5.6版本的按库并⾏策略

###### 配置为 LOGICAL_CLOCK，表示的就是类似MariaDB的策略。不过，MySQL 5.7这个策 略，针对并⾏度做了优化

##### 策略思想

###### 1. 同时处于prepare状态的事务，在备库执⾏时是可以并⾏的；

######  2. 处于prepare状态的事务，与处于commit状态的事务之间，在备库执⾏时也是可以并⾏的。

##### 相关参数配置

###### 1. binlog_group_commit_sync_delay参数，表示延迟多少微秒后才调⽤fsync;
2. binlog_group_commit_sync_no_delay_count参数，表示累积多少次以后才调⽤fsync

###### 这两个参数是⽤于故意拉⻓binlog从write到fsync的时间，以此减少binlog的写盘次数。
在 MySQL 5.7的并⾏复制策略⾥，它们可以⽤来制造更多的“同时处于prepare阶段的事务”。这样 就增加了备库复制的并⾏度

#### MySQL版本5.7.22的策略

##### 基于 WRITESET的并⾏复制

###### 新增了⼀个参数binlog-transaction-dependency-tracking，⽤来控制是否启⽤这个新 策略。

###### 1. COMMIT_ORDER，表示 根据同时进⼊prepare和commit来判断是否可以并⾏的策略。 

###### 2. WRITESET，表示的是对于事务涉及更新的每⼀⾏，计算出这⼀⾏的hash值，组成集合 writeset。如果两个事务没有操作相同的⾏，也就是说它们的writeset没有交集，就可以并 ⾏。

######  3. WRITESET_SESSION，是在WRITESET的基础上多了⼀个约束，即在主库上同⼀个线程先 后执⾏的两个事务，在备库执⾏的时候，要保证相同的先后顺序。

### 主备切换

#### 主从复制双M情况下 可靠性优先策略

##### 1. 判断备库B现在的seconds_behind_master，如果⼩于某个值（⽐如5秒）继续下⼀步，否
则持续重试这⼀步；

##### 2. 把主库A改成只读状态，即把readonly设置为true； 

##### 3. 判断备库B的seconds_behind_master的值，直到这个值变成0为⽌； 

##### 4. 把备库B改成可读写状态，也就是把readonly 设置为false；

##### 5. 把业务请求切到备库B。 

##### 这个切换流程，⼀般是由专⻔的HA系统来完成的，我们暂时称之为可靠性优先流程。（系统有不可用时间）

#### 主从复制双M情况下 可用性优先策略

##### 直接切换， 把步骤4、5调整到最开始执行（系统可能数据不一致）

##### 使用row格式的binlog时，数据不一致，问题更容易发现

##### 一般情况下不建议使用该方案

#### 主库异常的判定方法

##### 查表判断

###### 不完全准确 受到并发查询线程上限的影响（配置innodb_thread_concurrency参数，进入锁等待后，并发线程的计数会减一）

##### 更新判断

###### 同样受并发线程上限影响，双M配置主备需要安排更新不同行

##### 内部统计

###### file_summary_by_event_name表⾥统计了每次IO请求的时间

### 主备延迟

#### 产生原因与处理方案

##### 备库机器性能低于主库（多备同机/硬件配置/参数配置不同等）

###### 备库采用双非1配置，可以略微降低IO压力

###### 理想来说应该 主备库选⽤相同规格的机器，并且做对称部署

##### 备库压力大 ( 运营以及分析业务在备库执行导致 )

###### 采用一主多从的方式多机器提供读服务

###### 通过binglog输出到外部系统，通过外部系统如hadoop等来提供统计查询能力

##### 大事务（如一次性大批删除、大表DDL）

###### 小批量轮番删除

###### 计划内DDL、新建临时表同步数据过去，追上了再切换

##### 主库DML语句并发⼤,从库qps⾼ ；、从库上在进⾏备份操作 、设置的是延迟备库 、备库空间不⾜的情况下 

##### 表上⽆主键的情况(主库利⽤索引更改数据,备库回放只能⽤全表扫描,这种情况可以调整slav 
e_rows_search_algorithms参数适当优化下)

#### 主从延时过长业务解决方案

##### 强制读取主库

###### 业务可以忍受的情况下忽略

###### 一般会伴随一个负责管理后端的组建，比如 Zookeeper

##### sleep方案

###### 延时一段时间后再查询写入的信息，也可以将该方案做在业务前端

##### 选择性读取主库

###### 加中间件层：维护一个写请求的key，读取的时候存在则走此处，一定时间后删除

###### 加缓存层： 维护一个写请求的key，失效时长主从延迟时长，读取的时候存在则路由到主库

##### 分库、打开从库的并行复制

## 高可用架构

### 一主多从的主备切换

#### 基于位点的主备切换（主库故障T时刻的binlog位点），需要跳过错误

#### GTID  ( 5.6版本引入 )

##### GTID的全称是Global Transaction Identififier，也就是全局事务ID，是⼀个事务在提交的时候⽣ 成的，是这个事务的唯⼀标识

##### 官方定义 GTID=source_id:transaction_id,  可以理解为GTID=server_uuid:gno

##### server_uuid是⼀个实例第⼀次启动时⾃动⽣成的，是⼀个全局唯⼀的值； gno是⼀个整数，初始值是1，每次提交事务的时候分配给这个事务，并加1。

##### 加上参数 gtid_mode=on和enforce_gtid_consistency=on启动mysql实例就可以开启GTID模式

#### 基于GTID的主备切换

##### 实例B指定主库A'，基于主备协议建立连接，并把 GTID集合set_b发给A'，

##### 实例A'算出set_a与set_b的差集，在set_a而不在set_b的GTID集合，判断A'的本地是否包含了这个差集需要的所有binlog事务

###### 如果不包含，表示A'已经删除B需要的binlog，直接返回错误

###### 如果全包含，A'从自己binlog中，找出第一个不在 set_b的事务，发给B

##### 之后就从这个事务开始，往后读文件，按顺序取binlog发给B去执行

#### GTID和在线DDL

##### 双M模式的在线DDL

###### 实际从库 stop slave，而后从库执行DDL，查出GTID并在主库提交一条该GTID的空事务，跳过复制流程。执行主备切换后再来一遍

### 数据误删处理（重在预防）

#### 误删行数据

##### Flashback工具解析binlog

##### 线上数据不做删除，所有业务数据伪删除，除非归档

#### 误删库/表

##### 定期全量备份，实时备份binlog，恢复时跳过误删的记录，备份恢复功能定期演练

##### 延迟复制备库

#### 预防误删库/表

##### 账号分离

###### 只读权限，收紧权限

##### 制定操作规范

###### 先改名，后删除，只能删除固定格式名称的表等

## 维护处理

### kill相关知识

#### kill的方式

##### 结束某个线程    kill query thread_id 

##### 断开线程连接   kill connection thread_id

#### kill延时

##### 如果执行kill之后线程没有立即退出   因为线程没有执行到判断线程状态的逻辑；或者终止逻辑耗时较长

### 内存相关

#### 全表扫描对server 层的影响

##### 数据取发流程是 读取然后经过net_buffer批量轮流发送的

#### buffer pool

##### 数据页维护在内存buffer pool中还可以加速查询， 查询加速效果的重要指标: 内存命中率

##### InnoDB Buffer Pool的⼤⼩是由参数 innodb_buffer_pool_size确定的，⼀般建议设置成可⽤物 理内存的60%~80%。

##### InnoDB内存管理⽤的是最近最少使⽤ (Least Recently Used, LRU)算法，这个算法的核⼼就是淘汰最久未使⽤的数据。

##### 优化LRU淘汰算法，通过链表实现（ 5/3 青老区域 ），针对全表扫描做了优化

## join查询

### join查询流程

#### Index Nested-Loop Join，简称NLJ

##### 从驱动表查询一行数据R，提取关联字段值，再去被驱动表索引查询满足条件的数据，跟R组成一行，作为结果集合的一部分。如此重复步骤循环

##### 这种情况可以利用到被驱动表的索引，适合小表做驱动表，时间复杂度会好点

#### Simple Nested-Loop Join，MySQL也不用

##### 驱动表自索引查询一行数据R，主键取数据，再查询被驱动表（无索引，全表扫描），跟R组成行数据。循环其他行

#### Block Nested-Loop Join，简称BNL

##### 1. 把表t1的数据读⼊线程内存join_buffer中，由于我们这个语句中写的是select *，因此是把整 个表t1放⼊了内存；（如果jion_buffer放不下，可以分段放）

#####  2. 扫描表t2，把表t2中的每⼀⾏取出来，跟join_buffer中的数据做对⽐，满⾜join条件的，作 为结果集的⼀部分返回。

##### 与简单jion复杂度一样，但是内存操作节省磁盘io操作，join_buffer_size 越大效果越好

#### 小表的确定

##### 在决定哪个表做驱动表的时候，应该是两个表按照各⾃的条件过滤，过滤完 成之后，计算参与join的各个字段的总数据量，数据量⼩的那个表，就是“⼩表”，应该作为驱动 表

### join语句优化

#### Multi-Range Read优化 (MRR)

##### 这个优化的目的是尽量使用顺序读盘（回表是单行查询，一般情况主键递增的数据是顺序写入磁盘的，这样区间查询比较接近顺序读，能够提升读性能）

##### 根据索引a定位满足条件的记录，将id值放入read_rnd_buffer中，并对id进行性递增排序，之后在一次到主键ID的索引汇总查记录并返回结果（read_rnd_buffer_size参数控制空间大小）

#### Batched Key Acess(BKA)算法

##### MySQL5.6版本引入

###### 使用BKA依赖MRR，需要先设置 set optimizer_switch='mrr=on,mrr_cost_based=off,batched_key_access=on';

##### NLJ使用该方法优化，积累获取的驱动表ID，再批量获取被驱动表数据

##### BNL优化，可以尝试在被驱动表加索引转换为BKA算法，如果不适合，则可以提取满足条件的被驱动表数据组建临时表，给查询关联字段加上临时索引，触发BKA算法

#### 扩展-hash join，MySQL的优化器和执行器不支持

##### 可以考虑业务层做hash结构的比对

##### MySQL8.0做了相关支持

## 临时表相关

### 临时表特性

#### 1. 建表语法是create temporary table …。

####  2. ⼀个临时表只能被创建它的session访问，对其他线程不可⻅。所以，图中session A创建的 临时表t，对于session B就是不可⻅的。 

#### 3. 临时表可以与普通表同名。

####  4. session A内有同名的临时表和普通表的时候，show create语句，以及增删改查语句访问的 是临时表

### 临时表与binlog

#### 只在binlog_format=statment/mixed 的时候，binlog中才会记录临时表的操 作。

#### MySQL在记录binlog的时候，会把主库执⾏这个语句的线程id写到binlog中。这样，在备库的应 ⽤线程就能够知道执⾏每个语句的主库线程id，并利⽤这个线程id来构造临时表的 table_def_key

### 临时表的应⽤

#### 临时存储查询数据

#### 分库分表时候用临时表来汇总排序

### group by 优化

#### 1. 如果对group by语句的结果没有排序要求，要在语句后⾯加 order by null；

####  2. 尽量让group by过程⽤上表的索引，确认⽅法是explain结果⾥没有Using temporary 和 Using filesort；

#### 3. 如果group by需要统计的数据量不⼤，尽量只使⽤内存临时表；也可以通过适当调⼤ tmp_table_size参数，来避免⽤到磁盘临时表；

#### 4. 如果数据量实在太⼤，使⽤SQL_BIG_RESULT这个提示，来告诉优化器直接使⽤排序算法 得到group by的结果。

## 数据库引擎

### innoDB

#### 以上大部分内容都是基于InnoDB的，这里不多说

#### innoDB分区表

##### 分区表跟⽤户分表⽐起来，有两个绕不开的问题：⼀个是第⼀次访问的时候需要访问所有分区，另⼀个是共⽤MDL锁。

##### 如果要使⽤分区表，就不要创建太多的分区。

##### 怎么给分区表t创建⾃增主键。由于MySQL要求主键包含所有的分区字段，所以 肯定是要创建联合主键的

### Memory

#### 内存表索引

##### 使用hash索引， 索引与数据分开存放

##### 可以使用 alter table t1 add index a_btree_index using btree (id);的方式加 Btree索引

#### 内存表的锁

##### 不支持行锁，只支持表锁

#### 特性

##### 数据存放在内存中，如果机器重启，数据表结构与数据都会丢失

##### 在数据库重启之后，MySQL会往binlog⾥⾯写⼊⼀⾏DELETE FROM t1，来删除内存表，这样的话，主备复制的备库内存表也会被清除

##### 内存表在生产环境几乎不用

#### 与InnoDB的区别

##### 1. InnoDB表的数据总是有序存放的，⽽内存表的数据就是按照写⼊顺序存放的；

##### 2. 当数据⽂件有空洞的时候，InnoDB表在插⼊新数据的时候，为了保证数据有序性，只能在固定的位置写⼊新值，⽽内存表找到空位就可以插⼊新值；

##### 3. 数据位置发⽣变化的时候，InnoDB表只需要修改主键索引，⽽内存表需要修改所有索引；

##### 4. InnoDB表⽤主键索引查询时需要⾛⼀次索引查找，⽤普通索引查询的时候，需要⾛两次索引 查找。⽽内存表没有这个区别，所有索引的“地位”都是相同的。

#####  5. InnoDB⽀持变⻓数据类型，不同记录的⻓度可能不同；内存表不⽀持Blob 和 Text字段，并且即使定义了varchar(N)，实际也当作char(N)，也就是固定⻓度字符串来存储，因此内存表 的每⾏数据⻓度相同。

## 如何快速复制表

### mysqldump⽅法导出到临时文件

#### 命令与参数解析

##### mysqldump -h$host -P$port -u$user --add-locks --no-create-info --single-transaction --no-create-info --set-gtid-purged --result-file

##### 如此得到的数据是组织好的 insert 语句。   另外mysqldump提供了⼀个–tab参数，可以同时导出表结构定义⽂件和csv数据⽂件。

##### 1. –single-transaction的作⽤是，在导出数据的时候不需要对表db1.t加表锁，⽽是使⽤ START TRANSACTION WITH CONSISTENT SNAPSHOT的⽅法；

#####  2. –add-locks设置为0，表示在输出的⽂件结果⾥，不增加" LOCK TABLES t WRITE;" ；

#####  3. –no-create-info的意思是，不需要导出表结构；

#####  4. –set-gtid-purged=off表示的是，不输出跟GTID相关的信息；

#####  5. –result-file指定了输出⽂件的路径，其中client表示⽣成的⽂件是在客户端机器上的。

### 导出CSV文件

#### 导出到服务端本地

##### 命令与规则

###### select * from db1.t where a>900 into outfile '/server_tmp/t.csv';

###### select …into outfifile⽅法不会⽣成表结构⽂件, 所以我们导数据时还需要单 独的命令得到表结构定义

###### 1. 这条语句会将结果保存在服务端

######  2. into outfile指定了⽂件的⽣成位置（/server_tmp/），这个位置必须受参数secure_file_priv 的限制

###### 3. 这条命令不会帮你覆盖⽂件, 如果存在同名你文件执行会报错

######  4. 这条命令⽣成的⽂本⽂件中，原则上⼀个数据⾏对应⽂本⽂件的⼀⾏。数据中的换⾏符、制表符这类符号，前⾯都会跟上“\”这个转义符

#### 将服务端本地csv文件倒入库中

##### 命令与规则

###### load data infile '/server_tmp/t.csv' into table db2.t;

###### 主库binlog格式为statement时，除了记录该行命令，还会将文件写入binlog

###### 执行命令的时候如果 是 local file，则加载客户端本地文件数据，如果不带 local关键字，则会读取服务端文件

### 物理拷贝

#### 基础解释

##### 直接拷贝数据文件无效

###### ⼀个InnoDB表，除了包含这两个物理⽂件外，还需要在数据字典中注册。

###### 直接拷⻉这两 个⽂件的话，因为数据字典中没有db2.t这个表，系统是不会识别和接受它们的。

#### 具体操作方法

##### 导出方法

###### 在MySQL 5.6版本引⼊了可传输表空间(transportable tablespace)的⽅法，可以通过导出+导⼊表空间的⽅式，实现物理拷⻉表的功能

##### 导出流程

###### 1. 执⾏ create table r like t，创建⼀个相同表结构的空表；

######  2. 执⾏alter table r discard tablespace，这时候r.ibd⽂件会被删除；

###### 3. 执⾏flush table t for export，这时候db1⽬录下会⽣成⼀个t.cfg⽂件；

###### 4. 在db1⽬录下执⾏cp t.cfg r.cfg; cp t.ibd r.ibd；这两个命令；

######  5. 执⾏unlock tables，这时候t.cfg⽂件会被删除；

###### 6. 执⾏alter table r import tablespace，将这个r.ibd⽂件作为表r的新的表空间，由于这个⽂ 件的数据内容和t.ibd是相同的，所以表r中就有了和表t相同的数据。

## 分库分表

### 分库分表瓶颈条件

#### I/O瓶颈

##### 第一种：磁盘读IO瓶颈，热点数据太多，数据库缓存放不下，每次查询会产生大量的IO，降低查询速度->分库和垂直分表

##### 第二种：网络IO瓶颈，请求的数据太多，网络带宽不够 ->分库

#### CPU瓶颈

##### 第一种：SQL问题：如SQL中包含join,group by, order by，非索引字段条件查询等，增加CPU运算的操作->SQL优化，建立合适的索引，在业务Service层进行业务计算。

##### 第二种：单表数据量太大，查询时扫描的行太多，SQl效率低，增加CPU运算的操作。->水平分表。

#### 拆分条件

##### 分库分表之前，先尽力做力所能及的优化：升级硬件、升级网络、读写分离、索引优化，归档处理等。当数据量达到单表瓶颈后，在考虑分库分表。

##### 能不分就不分

##### 数据量过大，正常运维影响业务访问（DDL锁表影响业务的时候）

##### 随着业务发展，需要对某些字段垂直拆分

##### 数据量快速增长

### 拆分方式与中间件

#### 分库分表中间件（ Sharding-jdbc Mycat）

#### 拆分方式

##### 水平拆分

##### 垂直拆分

#### 动态扩容

##### 一次性分足库表 32*32=1024

##### 倍数增加机器 / 切换路由规则

##### 全局唯一ID生成机制

###### 基于单库的自增id

###### snowflake算法  时间戳-机房ID-机器ID-增长序列

### 分库分表后的问题

#### 事务一致性问题

##### 分布式事务、最终一致性方案等等

#### 跨节点关联查询join问题解决

##### 使用全局表（通用依赖的表每个库都存一份）

##### 字段冗余（反范式冗余部分数据）

##### 数据组装（代码层面查询组装数据）

##### ER分片（将关联数据路由到相同分片存储，适应后续使用）

#### 跨节点分页、排序、函数问题

##### 多分片数据统计性能问题（类ES）

#### 拆分迁移方案（扩容与迁移）

##### 停机维护

##### 双写迁移

## 参考资料

### MySQL实战45讲

### 深入浅出MySQL

### 高性能MySQL
